{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63e44ad5-f349-4914-ae4f-200c956b8c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all necessery libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d12b2cc-fb56-49c1-8cf2-199c7b540890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining here the transformations for dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize images to a fixed size\n",
    "    transforms.ToTensor(),        # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize pixel values between -1 and 1\n",
    "])\n",
    "\n",
    "\n",
    "# Here loading dataset from the directory\n",
    "train_data = ImageFolder(root='data/data/train', transform=transform)\n",
    "test_data = ImageFolder(root='data/data/test', transform=transform)\n",
    "\n",
    "\n",
    "# Creating here the DataLoaders for batching\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cb3dafc-5010-4cff-9a4c-7f66d42c6821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 3467\n",
      "Number of test samples: 8\n",
      "Class labels (train): ['accessories', 'jackets', 'jeans', 'knitwear', 'shirts', 'shoes', 'shorts', 'tees']\n"
     ]
    }
   ],
   "source": [
    "# Checking the number of images in the training and test datasets\n",
    "print(f'Number of training samples: {len(train_data)}')\n",
    "print(f'Number of test samples: {len(test_data)}')\n",
    "\n",
    "# Checking the class labels in the training data (should match your 7 folders)\n",
    "print(f'Class labels (train): {train_data.classes}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d626f961-8306-4271-b72d-95f2fd698163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the MLP model class:\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Define the architecture with fully connected layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # First hidden layer\n",
    "        self.relu1 = nn.ReLU()  # Activation function\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)  # Second hidden layer\n",
    "        self.relu2 = nn.ReLU()  # Activation function\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)  # Output layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten the input image\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Forward pass through the layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "622c0c49-a68d-49f8-84d1-6b3383788acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the hyperparameters \n",
    "input_size = 64 * 64 * 3  # Image size (64x64 with 3 color channels)\n",
    "hidden_size = 128  # Number of neurons in hidden layers\n",
    "output_size = 8  # Number of classes (for your 8 categories)\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec172909-4a65-4250-b761-b132435cfae4",
   "metadata": {},
   "source": [
    "Initializing the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83d750ca-a570-4fb4-b834-aa4ce40d6532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MLP(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e381b563-b59f-4928-a59b-6a48ba11cd5e",
   "metadata": {},
   "source": [
    "Training the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41f34d67-f19c-4982-a519-88161e7540d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/109], Loss: 0.8418\n",
      "Epoch [2/10], Step [100/109], Loss: 0.5746\n",
      "Epoch [3/10], Step [100/109], Loss: 0.4737\n",
      "Epoch [4/10], Step [100/109], Loss: 0.4310\n",
      "Epoch [5/10], Step [100/109], Loss: 0.3908\n",
      "Epoch [6/10], Step [100/109], Loss: 0.3450\n",
      "Epoch [7/10], Step [100/109], Loss: 0.2962\n",
      "Epoch [8/10], Step [100/109], Loss: 0.3086\n",
      "Epoch [9/10], Step [100/109], Loss: 0.2739\n",
      "Epoch [10/10], Step [100/109], Loss: 0.2227\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs/mlp_experiment')\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "       \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "       \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
    "            writer.add_scalar('Training Loss', running_loss / 100, epoch * len(train_loader) + i)\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af063ce-dacd-40a7-afd9-63db69f84456",
   "metadata": {},
   "source": [
    "Evaluating the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58377976-810f-4755-ac0e-78bb04f4aaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 25.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "accuracy = (correct / total) * 100\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Saving the trained model\n",
    "torch.save(model.state_dict(), 'mlp_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99f3cae-c4b4-4688-8e74-533d85972a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
